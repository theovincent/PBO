{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FQI on Bicycle\n",
    "\n",
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:30:06.670302Z",
     "iopub.status.busy": "2022-09-25T10:30:06.670118Z",
     "iopub.status.idle": "2022-09-25T10:30:07.382313Z",
     "shell.execute_reply": "2022-09-25T10:30:07.381816Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import os\n",
    "import json\n",
    "\n",
    "parameters = json.load(open(\"parameters.json\"))\n",
    "env_seed = parameters[\"env_seed\"]\n",
    "gamma = parameters[\"gamma\"]\n",
    "# Sample collection\n",
    "n_samples = parameters[\"n_samples\"]\n",
    "\n",
    "# Trainings\n",
    "layers_dimension = parameters[\"layers_dimension\"]\n",
    "max_bellman_iterations = parameters[\"max_bellman_iterations\"]\n",
    "batch_size_samples = n_samples\n",
    "fitting_steps = parameters[\"fitting_steps_fqi\"]\n",
    "learning_rate = {\"first\": parameters[\"starting_lr_fqi\"], \"last\": parameters[\"ending_lr_fqi\"], \"duration\": fitting_steps * n_samples // batch_size_samples}\n",
    "max_patience = parameters[\"patience\"]\n",
    "\n",
    "# Visualisation of errors and performances\n",
    "n_omegas = parameters[\"n_omegas\"]\n",
    "n_thetas = parameters[\"n_thetas\"]\n",
    "n_simulations = parameters[\"n_simulations\"]\n",
    "horizon = parameters[\"horizon\"]\n",
    "\n",
    "# Search for an unused seed\n",
    "max_used_seed = 0\n",
    "if not os.path.exists(\"figures/data/FQI/\"):\n",
    "    os.makedirs(\"figures/data/FQI/\")\n",
    "for file in os.listdir(\"figures/data/FQI/\"):\n",
    "    if int(file.split(\"_\")[0]) == max_bellman_iterations and int(file.split(\"_\")[2][:-4]) > max_used_seed:\n",
    "        max_used_seed = int(file.split(\"_\")[2][:-4])\n",
    "max_used_seed\n",
    "\n",
    "# keys\n",
    "seed = 0 # max_used_seed + 1\n",
    "env_key = jax.random.PRNGKey(env_seed)\n",
    "env_key, sample_key = jax.random.split(env_key)\n",
    "key = jax.random.PRNGKey(seed)\n",
    "shuffle_key, q_network_key, _ = jax.random.split(key, 3) # 3 keys are generated to be coherent with the other trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:30:07.385783Z",
     "iopub.status.busy": "2022-09-25T10:30:07.385568Z",
     "iopub.status.idle": "2022-09-25T10:30:07.671596Z",
     "shell.execute_reply": "2022-09-25T10:30:07.671114Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pbo.environments.bicycle import BicycleEnv\n",
    "\n",
    "\n",
    "env = BicycleEnv(env_key, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples on the mesh and with a uniform policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:30:07.673849Z",
     "iopub.status.busy": "2022-09-25T10:30:07.673682Z",
     "iopub.status.idle": "2022-09-25T10:30:17.505000Z",
     "shell.execute_reply": "2022-09-25T10:30:17.504525Z"
    }
   },
   "outputs": [],
   "source": [
    "from pbo.sample_collection.replay_buffer import ReplayBuffer\n",
    "\n",
    "\n",
    "replay_buffer = ReplayBuffer()\n",
    "\n",
    "env.reset()\n",
    "n_episodes = 0\n",
    "n_steps = 0\n",
    "positions = [[env.position]]\n",
    "\n",
    "for idx_sample in range(n_samples):\n",
    "    state = env.state\n",
    "    \n",
    "    sample_key, key = jax.random.split(sample_key)\n",
    "    action = jax.random.choice(key, env.actions_on_max)\n",
    "    \n",
    "    next_state, reward, absorbing, _ = env.step(action)\n",
    "    n_steps += 1\n",
    "    positions[n_episodes].append(env.position)\n",
    "\n",
    "    replay_buffer.add(state, action, reward, next_state, absorbing)\n",
    "\n",
    "    if absorbing[0] or n_steps >= 20:\n",
    "        env.reset()        \n",
    "        positions[n_episodes] = np.array(positions[n_episodes])\n",
    "        positions.append([])\n",
    "        n_episodes += 1\n",
    "        n_steps = 0\n",
    "\n",
    "replay_buffer.cast_to_jax_array()\n",
    "# assert sum(replay_buffer.rewards == -1) > 0, \"No negative reward has been sampled, please do something!\"\n",
    "print(f\"Number of episodes: {n_episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:30:17.506882Z",
     "iopub.status.busy": "2022-09-25T10:30:17.506713Z",
     "iopub.status.idle": "2022-09-25T10:30:22.539477Z",
     "shell.execute_reply": "2022-09-25T10:30:22.539022Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    ax1.plot(positions[episode][:, 0], positions[episode][:, 1], color=\"black\")\n",
    "\n",
    "    for step in range(len(positions[episode])):\n",
    "        ax2.plot(positions[episode][step, [0, 2]], positions[episode][step, [1, 3]], color=\"black\")\n",
    "\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.spines[\"bottom\"].set_visible(False)\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_title(f\"Back tire\")\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"y\")\n",
    "ax2.set_title(f\"Bicycle\", y=0, pad=-30, verticalalignment=\"top\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:30:22.541702Z",
     "iopub.status.busy": "2022-09-25T10:30:22.541503Z",
     "iopub.status.idle": "2022-09-25T10:30:23.053410Z",
     "shell.execute_reply": "2022-09-25T10:30:23.052951Z"
    }
   },
   "outputs": [],
   "source": [
    "omegas = jnp.linspace(replay_buffer.states[:, 0].min(), replay_buffer.states[:, 0].max(), n_omegas)\n",
    "omega_dots = jnp.linspace(replay_buffer.states[:, 1].min(), replay_buffer.states[:, 1].max(), n_omegas)\n",
    "\n",
    "sample_key, key = jax.random.split(sample_key)\n",
    "sample_omegas_omega_dots = jax.random.choice(key, replay_buffer.states[:, :2], shape=(min(n_samples // 100, 50),), replace=False)\n",
    "\n",
    "thetas = jnp.linspace(replay_buffer.states[:, 2].min(), replay_buffer.states[:, 2].max(), n_thetas)\n",
    "theta_dots = jnp.linspace(replay_buffer.states[:, 3].min(), replay_buffer.states[:, 3].max(), n_thetas)\n",
    "\n",
    "sample_key, key = jax.random.split(sample_key)\n",
    "sample_thetas_theta_dots = jax.random.choice(key, replay_buffer.states[:, 2:5], shape=(min(n_samples // 100, 50),), replace=False)\n",
    "\n",
    "_ = plt.hist(np.array(replay_buffer.rewards.flatten()), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:30:23.055297Z",
     "iopub.status.busy": "2022-09-25T10:30:23.055162Z",
     "iopub.status.idle": "2022-09-25T10:32:16.947288Z",
     "shell.execute_reply": "2022-09-25T10:32:16.946763Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pbo.utils.two_dimesions_mesh import TwoDimesionsMesh\n",
    "from pbo.sample_collection.dataloader import SampleDataLoader\n",
    "from pbo.networks.learnable_q import FullyConnectedQ\n",
    "\n",
    "\n",
    "data_loader_samples = SampleDataLoader(replay_buffer, batch_size_samples, shuffle_key)\n",
    "q = FullyConnectedQ(\n",
    "    state_dim=4,\n",
    "    action_dim=2,\n",
    "    actions_on_max=env.actions_on_max,\n",
    "    gamma=gamma,\n",
    "    network_key=q_network_key,\n",
    "    layers_dimension=layers_dimension,\n",
    "    zero_initializer=True,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "omega_visu_mesh = TwoDimesionsMesh(omegas, omega_dots, sleeping_time=0, axis_equal=False, zero_centered=True)\n",
    "theta_visu_mesh = TwoDimesionsMesh(thetas, theta_dots, sleeping_time=0, axis_equal=False, zero_centered=True)\n",
    "l2_losses = np.ones((max_bellman_iterations, fitting_steps)) * np.nan\n",
    "metrics = np.ones((max_bellman_iterations + 1, n_simulations, 2)) * np.nan\n",
    "metrics[0] = env.evaluate(q, q.params, horizon, n_simulations)\n",
    "\n",
    "for bellman_iteration in range(1, max_bellman_iterations + 1):\n",
    "    q.reset_optimizer()\n",
    "    params_target = q.params\n",
    "    best_loss = float('inf')\n",
    "    patience = 0\n",
    "\n",
    "    for step in range(fitting_steps):\n",
    "        cumulative_l2_loss = 0\n",
    "        \n",
    "        data_loader_samples.shuffle()\n",
    "        for batch_samples in data_loader_samples:\n",
    "            q.params, q.optimizer_state, l2_loss = q.learn_on_batch(q.params, params_target, q.optimizer_state, batch_samples)\n",
    "            cumulative_l2_loss += l2_loss\n",
    "\n",
    "        l2_losses[bellman_iteration - 1, step] = cumulative_l2_loss\n",
    "        if cumulative_l2_loss < best_loss:\n",
    "            patience = 0\n",
    "            best_loss = cumulative_l2_loss\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    metric = env.evaluate(q, q.params, horizon, n_simulations)\n",
    "    metrics[bellman_iteration] = metric\n",
    "\n",
    "    d_on_omegas = env.best_action_on_omegas(q, q.params, omegas, omega_dots, sample_thetas_theta_dots)\n",
    "    T_on_thetas = env.best_action_on_thetas(q, q.params, sample_omegas_omega_dots, thetas, theta_dots)\n",
    "\n",
    "    omega_visu_mesh.set_values(d_on_omegas)\n",
    "    omega_visu_mesh.show(r\"d on some sampled $\\theta$ and $\\dot{\\theta}$,\" + f\"\\nl2 loss: {str(jnp.round(cumulative_l2_loss, 5))}, iteration {bellman_iteration}, step {step + 1}.\", xlabel=r\"$\\omega$\", ylabel=r\"$\\dot{\\omega}$\")\n",
    "    theta_visu_mesh.set_values(T_on_thetas)\n",
    "    theta_visu_mesh.show(r\"T on some sampled $\\omega$ and $\\dot{\\omega}$\" + f\"\\n{metric[:, 0].mean()} steps, V = {str(jnp.round(metric[:, 1].mean(), 1))}.\", xlabel=r\"$\\theta$\", ylabel=r\"$\\dot{\\theta}$\", clear=False)\n",
    "\n",
    "\n",
    "for bellman_iteration in range(0, max_bellman_iterations, max(max_bellman_iterations // 10, 1)):\n",
    "    plt.plot(l2_losses[bellman_iteration], label=f\"Iteration {bellman_iteration + 1}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"fitting step\")\n",
    "plt.ylabel(r\"$(\\Gamma^*Q_i - Q_{i +  1})^2$\")\n",
    "plt.title(\"Training losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:32:16.949529Z",
     "iopub.status.busy": "2022-09-25T10:32:16.949391Z",
     "iopub.status.idle": "2022-09-25T10:32:17.018972Z",
     "shell.execute_reply": "2022-09-25T10:32:17.018356Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, max_bellman_iterations + 1), [np.argmin(l) for l in l2_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:32:17.021224Z",
     "iopub.status.busy": "2022-09-25T10:32:17.021088Z",
     "iopub.status.idle": "2022-09-25T10:32:17.132003Z",
     "shell.execute_reply": "2022-09-25T10:32:17.131481Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.plot(range(max_bellman_iterations + 1), metrics[:, :, 0].mean(axis=1))\n",
    "ax1.set_xticks(range(max_bellman_iterations + 1))\n",
    "ax2.plot(range(max_bellman_iterations + 1), metrics[:, :, 1].mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:32:17.134258Z",
     "iopub.status.busy": "2022-09-25T10:32:17.134121Z",
     "iopub.status.idle": "2022-09-25T10:32:19.934650Z",
     "shell.execute_reply": "2022-09-25T10:32:19.934125Z"
    }
   },
   "outputs": [],
   "source": [
    "positions = env.collect_positions(q, q.params, horizon)\n",
    "\n",
    "plt.plot(positions[:, 0], positions[:, 1], color=\"black\")\n",
    "plt.axis(\"equal\")\n",
    "_ = plt.title(f\"{positions.shape[0]} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:32:19.936828Z",
     "iopub.status.busy": "2022-09-25T10:32:19.936693Z",
     "iopub.status.idle": "2022-09-25T10:32:19.947200Z",
     "shell.execute_reply": "2022-09-25T10:32:19.946762Z"
    }
   },
   "outputs": [],
   "source": [
    "# env.simulate(q, q.params, horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T10:32:19.949343Z",
     "iopub.status.busy": "2022-09-25T10:32:19.949212Z",
     "iopub.status.idle": "2022-09-25T10:32:19.959388Z",
     "shell.execute_reply": "2022-09-25T10:32:19.958947Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(f\"figures/data/FQI/{max_bellman_iterations}_metrics_{seed}.npy\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env_cpu': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "af5525a3273d35d601ae265c5d3634806dd61a1c4d085ae098611a6832982bdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
