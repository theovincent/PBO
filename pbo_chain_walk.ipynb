{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PBO learnt on several iterations and one weigth one the chain walk environment\n",
                "\n",
                "## Define parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import numpy as np\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "\n",
                "# keys\n",
                "seed = 0\n",
                "key = jax.random.PRNGKey(seed)\n",
                "env_key, key = jax.random.split(key)\n",
                "shuffle_key, q_network_key, random_weights_key, pbo_network_key = jax.random.split(key, 4)\n",
                "\n",
                "# Box over states and actions\n",
                "n_states = 17\n",
                "n_actions = 2\n",
                "n_repetitions = 10\n",
                "sucess_probability = 0.9\n",
                "gamma = 0.9\n",
                "\n",
                "# Weights collection\n",
                "n_weights = 500\n",
                "\n",
                "# Trainings\n",
                "max_bellman_iterations = 20\n",
                "\n",
                "## Linear PBO\n",
                "add_infinity_linear = True\n",
                "add_infinity_non_linear = False\n",
                "fitting_steps = 2\n",
                "training_steps = 200\n",
                "batch_size_samples = n_states\n",
                "batch_size_weights = n_weights\n",
                "learning_rate = {\"first\": 0.01, \"last\": 0.001, \"duration\": training_steps * fitting_steps * n_actions * n_repetitions}\n",
                "\n",
                "## Q-learning\n",
                "fitting_steps_q = fitting_steps * training_steps\n",
                "learning_rate_q = {\"first\": 0.01, \"last\": 0.001, \"duration\": fitting_steps_q * max_bellman_iterations * n_actions * n_repetitions}\n",
                "\n",
                "# Visualisation of errors and performances\n",
                "max_bellman_iterations_validation = max_bellman_iterations + 20\n",
                "horizon = 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pbo.environment.chain_walk import ChainWalkEnv\n",
                "\n",
                "states = np.arange(n_states)\n",
                "actions = np.arange(n_actions)\n",
                "states_boxes = (np.arange(n_states + 1 + 1) - 0.5)[:-1]\n",
                "actions_boxes = (np.arange(n_actions + 1 + 1) - 0.5)[:-1]\n",
                "\n",
                "env = ChainWalkEnv(env_key, n_states, sucess_probability, gamma)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Collect samples"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Samples on the mesh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pbo.sample_collection.replay_buffer import ReplayBuffer\n",
                "\n",
                "\n",
                "n_samples = n_states * n_actions * n_repetitions\n",
                "replay_buffer = ReplayBuffer()\n",
                "\n",
                "for state in states:\n",
                "    for action in actions:\n",
                "        # Need to repeat the samples to capture the randomness\n",
                "        for _ in range(n_repetitions):\n",
                "            env.reset(jnp.array([state]))\n",
                "            next_state, reward, _, _ = env.step(jnp.array([action]))\n",
                "\n",
                "            replay_buffer.add(jnp.array([state]), jnp.array([action]), reward, next_state)\n",
                "\n",
                "replay_buffer.cast_to_jax_array()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize samples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 2 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from pbo.sample_collection.count_samples import count_samples\n",
                "from pbo.utils.two_dimesions_mesh import TwoDimesionsMesh\n",
                "\n",
                "\n",
                "samples_count, n_outside_boxes = count_samples(replay_buffer.states, replay_buffer.actions, states_boxes, actions_boxes)\n",
                "samples_visu_mesh = TwoDimesionsMesh(states, actions, sleeping_time=0)\n",
                "\n",
                "samples_visu_mesh.set_values(samples_count, zeros_to_nan=True)\n",
                "samples_visu_mesh.show(\n",
                "    f\"Samples repartition, \\n{int(100 * n_outside_boxes / n_samples)}% are outside the box.\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimal Q function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEYCAYAAACp5wpbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbMUlEQVR4nO3deZSsVXnv8e8PDoIHGT2CyCA4R73gQJDrjBiDBsWo18CNXlGvw12Ks8ZpOeTqirNBTVxBQYwCUXH2RoQYlMQBZRJQUBEZDoN4IgKKIpzz3D/et7E41Ftdw9t0Hfh+1qp1urp2PbW7T3U/vfd+97NTVUiSNMxGy90BSdL8MklIkjqZJCRJnUwSkqROJglJUqcVy90BSdJwf77P5vVfv1o70XNOPfO6r1XVfn31wSQhSXNqza/WcvLXdproOZvs8LNVffbB6SZJUidHEpI0t4q1tW5Ze2CSkKQ5VcA6lrcqhklCkubYOhxJSJKGKIq1y1xfzyQhSXPM6SZJ0lAFrDVJSJK6OJKQJA1V4JqEJKnb8l7bZJKQpLlVlGsSkqQOBWuX+YRpk4Qkzalmx/XyMklI0twKa8my9sAkIUlzqoB1TjdJkro4kpAkDdXsuDZJSJI6rCuThCRpCEcSkqRORVi7zKdMmyQkaY453SRJGsrpJknSCGFtOd0kSRqiKcthkpAkdXC6SZI0VJXTTZKkEdY5kpAkDdNc3eRIQpI0lNNNkqQOXt0kSRpprTuuJUnDWLtJkjTSOtckJEnDeHWTJKlTEdckJEndvLpJkjRUFe6TkCR1iWU5JEnDFcs/kljeV5ckjbSWjSa6jSPJS5OcneSHSV42qq0jCUmaU0V6P+M6yf2B5wF7AX8Ajkvylao6b1h7RxKSNMeWYCTxJ8DJVXVtVd0AfBN4Sldjk4Qkzami2XE9yQ1YleSUgdvz1wt7NvCIJHdMshJ4ArBzVx+cbpKkuZVpji9dU1V7dj1YVeckeSdwPPBb4AxgbVd7RxKSNKemHEksHrfq8Kp6cFU9ErgS+ElXW0cSkjTHphhJLCrJdlV1RZJdaNYj9u5qa5KQpDlVlaWqAvvZJHcErgdeVFW/7mpokpCkObYUm+mq6hHjtjVJSNKcao4vtSyHJGmoLHtZDpOEJM2p5uomRxKSpA6eTCdJGmopajdNyiQhSXNsuU+mc8e1JKmTIwlJmlPN8aVON0mSOrgmIUkaqlm49uomSVKHpSjwNwmThCTNKTfTSZJGcLpJkjSCBf4kSUN5CawkaSSnmyRJQ1m7SZI0kmsSkqShvARWkjSSaxKSpOHKNQlJUofCNQlJ0giOJCRJQ7lwLUkaySQhSRrKzXSSpJFcuJYkDVdON0mSOrhwLUkaySQhSRrKhWtJ0khlkpAkdfHqJknSUDUHVzctbw1aSdJIVZnoNo4kL0/ywyRnJzkmyWZdbU0SkjS3moXrSW6LRkx2BF4C7FlV9wc2Bg7sau90kyTNsSVauF4B3D7J9cBK4NJRDSVJc2jKzXSrkpwycP+wqjrsxphVlyR5D3AR8Dvg+Ko6viuYSUKS5lU1i9cTWlNVe3Y9mGQb4ABgN+DXwGeSPKOqPjmsvWsSkjTH1pGJbmN4LPDzqvplVV0PfA54aFdjRxKSNKeKJVmTuAjYO8lKmummfYFTuhqbJCRpbvVflqOqTk5yLHAacANwOnBYV3uThCTNsSnWJMaIWW8G3jxOW5OEJM0xazdJkoaqMklIkkZY7tpNJglJmmNLsSYxCZOEJM0xp5skSUMV41d2XSomCUmaY8s822SSkKS55dVNkqSRXLiWJHVxJCFJ6uQlsJKkoZaoCuxETBKSNK8KWOYk4aFDukUk2SXJb5JsvASx35Jk6KlaU8TaPslJSa5J8t4+Yk7w2r9Jcrdb8jU1/6omu/XNJKGhkhyc5Kwk1ya5PMmHk2w9wfMvSPLYhftVdVFV3aGq1i5Jh/vzfGANsGVVvXKpXiTJN5L878HPtd+f85fqNbWBqglvPTNJ6GaSvBJ4J/BqYCtgb+CuwAlJbrecfbsF3BX4UdVyLxdKQLvjepJb30wSuokkWwJvBQ6pquOq6vqqugB4OrAr8Iy23VuSHJvkU+3UzGlJ9mgf+wSwC/DldgrlNUl2TVJJVrRtvpHkbUm+3bb5cpI7JjkqydVJvp9k14F+HZrk4vaxU5M8YoKv6dVJLktyaZLntP24x5B2RwLPAl7T9umxSY5M8raBNo9Osnrg/gVJXpXkzCRXtd+PzQYePyDJGW2/f5ZkvyRvBx4BfKh9nQ+1bW/sV5Ktkvxzkl8muTDJG5Ns1D52cJL/TPKeJFcm+XmSx4/7/dAGxpGE5sxDgc1oDke/UVX9BvhX4M8GPn0A8BlgW+Bo4AtJNqmqZ9Kco/vEdgrlXR2vdSDwTGBH4O7Ad4CPtfHO4aYnZ30feMDAa31m8JdxlyT7Aa9q+31PmkPgh6qqg4GjgHe1/f63xeK3ng7sB+wG7A4c3L72XsA/04zItgYeCVxQVW8A/gN4cfs6Lx4S84M0o7i7AY8C/hfw7IHHHwL8GFgFvAs4PMnyrnDqVskkofWtAtZU1Q1DHrusfXzBqVV1bFVdD7yPJrnsPcFrfayqflZVVwFfBX5WVf/WvvZngAcuNKyqT1bVf1XVDVX1XmBT4N5jvMbT29c5u6p+C7xlgv6N6wNVdWlV/Qr4Mk0yA3gucERVnVBV66rqkqo6d7Fg7eL+gcDrquqadiT3XpqEuuDCqvpIu8bzcWAHYPv+viTNhbYsh9NNmidrgFUL00Lr2aF9fMHFCx9U1TpgNXCXCV7rFwMf/27I/Tss3GmndM5pp3R+TfNX9mDC6nKXwX4CF07Qv3FdPvDxtfyx3zsDP5si3ipgE27a1wtpRlw3e82qurb98A7o1sfpJs2Z7wDXAU8Z/GSSOwCPB74+8OmdBx7fCNgJuLT9VG9v13b94TU0o4Jtqmpr4CpgnD+bLhvsJ81aySR+C6wcuH/nCZ57Mc002jCjvj9rgOtpFtEX7AJcMsFr61YjE976ZZLQTbRTP28FPtgusm7SLiB/mmak8ImB5g9O8pR21PEymuTy3faxX9DMp/dhC+AG4JfAiiRvArYc87mfBg5Oct8kK7npOsc4zgCekGTbJHem+TrHdTjw7CT7JtkoyY5J7tM+1vn9aaeQPg28PckWSe4KvALoZS+INjAb0kiifaOP+8OpDVS70Px64D3A1cDJNH8V71tV1w00/SLwV8CVNPPlT2nXJwD+Dnhjkl8nedWMXfoacBzwE5ppl99z0ymkUV/LV4G/B/4dOK/9dxKfAH4AXAAcD3xq3CdW1fdoFpvfTzPy+SZ/HB0cCjytvTrpA0OefgjNKOZ84D9pFuuPmLDvujVY5iSRxS4HT3I08EJgLc0VJlsCh1bVu/vvjjYUSd4C3KOqnrHcfZlUkgLuWVXnLXdfpFE23XWn2uHNL5noORc+529Orao9++rDOCOJ+1bV1cCTaa5A2Y2bXmUhSVoiG0JZjk2SbEKTJL7UTics2pUkRyS5IsnZM/ZRkm67NoA1iX+imY/dHDipXUS7eoznHUmzwUi3QlX1lg1xqgmgquJUkzYYlcluPVu0VHhVfQAYXFi7MMk+YzzvpMGyCpKkyWXeDx1KsinwVJq6PYPt/7aPDiR5Pk3lTTZfmQff5x6j68ed+7tt+nhZAK6/rr/jNDa6bvE2k9j4+sXbjGuj69b1Fit/GLYRezp1fX9fZFb0939Zt9ukt1gA627X35Xm63osr7h20/5ibXS7/or7brPp73qLdecV1y7eaEwbjbkH4dQzr1tTVXfq5UWXaAppEuP8ZH2R5vK9U2mug+9VVR0GHAaw5x6b1fe+Nnqv00N/8NTeXvvy8+/YW6zNL+j3mIQtVvf3i32LC3/fW6wVF/2yt1g3rO5vb9iKVdv1Fmvtzv1Wt/jtLisXbzSma3bp7332m7v299tn892u6i3Wk3c7s7dYr111Wm+xbp/xsurGO/y0x139SzOFNIlxksROVeXagiQth2UeSYwzDv52kv+25D2RJN3cBnB108OBU5P8uK2Zf1aSRceDSY6hqQN07ySrkzx31s5K0m3OMieJcaabpjrMpKoOmuZ5kqRWsexrEouOJKrqQpoDU57Y3rZuPydJWmKpyW6Lxkvu3Z6WuHC7OsnLutovmiSSvJTmtK7t2tsnkxwy9lcoSZpez9NNVfXjqnpAVT0AeDDNGSif72o/znTTc4GHtKd6keSdNGsNHxzjuZKk+bUvzYmQnbND4ySJ0FSAXbCWpTjZQpJ0M0u84/pA4JhRDcZJEh8DTk6yMBx5Ms1hKsvi67sf3Vusd9zlQb3F+sKOu/cWC+CKn2/VW6xrt+9vM9cWd96pt1ib33nb3mJx8S8WbzOmOuWs3mIBbHn5jos3GtPKy/vZyAuw8heb9Rbrmku37i3WJy55WG+xTrjbfRZvNKZv7/HZ3mJNZPKF61VJThm4f1i7afkmktwOeBLwulHBxqnd9L4k36C5FBbg2VV1+vj9lSRNZbrLWteMeZ7E44HTqmrkX1idSSLJllV1dZJtaarAXjDw2LZV9avx+itJmtrSTTcdxCJTTTB6JHE0sD9NzabBbqa939f5xZKkDkuxJpFkc+DPgBcs1rYzSVTV/u2/u/XXNUnSRJYgSbRXq45V4XScfRJfH+dzkqQlMK+1m5Js1q5HrEqyTZJt29uuwFiXayTZr635dF6S1/bUZ0m6TZh0t/VSTE2NWpN4AfAy4C406xIL12FdDXxoscBJNgb+gWbeazXw/SRfqqofzdJhSbpNmdfzJKrqUODQJIdU1TS7q/cCzquq8wGS/AtwAGCSkKRxbQAn061LsnVV/RogyTbAQVX1j4s8b0fg4oH7q4GHrN9o8PhS4LqNd/jp2WP0aRyrgDWjm1zUY6wv9BhrbLeFWH3Hu+VjXbxoi+WJ9a0eY43vFv3+T1CJdNFYE5wJeO/xmy5u7s+4Bp5XVf+wcKeqrkzyPGCxJDGWweNLk5wy5iaQRRnr1hGr73jGWr5Yfceb51h9xLnRBpAkNk6Sqiq4ca1hnOPYLwF2Hri/U/s5SdI4lmgxehLjJInjgE8l+af2/guAr47xvO8D90yyG01yOBD4n1P1UpJuqzaAJPE3NGsGL2zvnwncebEnVdUNSV4MfI1mOu+IqvrhIk+7WRGqGRjr1hGr73jGWr5Yfce7LcRa9iSRdhZpdKPkgTSjgKcD5wOfrapFL4OVJE1vsx13rru+8BUTPecnb3rFqX2uI40q8HcvmgJQB9Gs+n8KoKr26evFJUnzbdR007nAfwD7V9V5AElefov0SpLUWObpplG1m54CXAacmOQjSfZliU6k67N8R5IjklyRZKb9Fkl2TnJikh8l+WF71vcs8TZL8r0kP2jjvXXGeBsnOT3JV2aJ08a6IMlZ7aHoM12+l2TrJMcmOTfJOUn++5RxJjqsfYx4L2+/72cnOSbJ1CfuJHlpG+eH0/Rp2Hu0LXlzQpKftv9uM0Os/9H2bV2SsacdOmK9u/2/PDPJ55NsPUOs/9vGOSPJ8UnuMkvfBh57ZZJKsmqGvr0lySUD77cnzNKvJIe037cfJnnXOLGGmoOyHJ1Joqq+UFUHAvcBTqQp0bFdkg8neVxfHcgfy3c8HrgvcFCS+84Q8khgvx66dgPwyqq6L7A38KIZ+3Ud8Jiq2gN4ALBfkr1niPdS4JwZnr++fdrD0WedyzwUOK6q7gPswZR9nPSw9lGS7Ai8BNizqu5PcyHFgVPGuj/wPJqKAnsA+ye5x4RhjuTm79HXAl+vqnsCX2/vTxvrbJo/8k7qoV8nAPevqt2Bn7DIKWaLxHp3Ve3e/p9+BXjTjH0jyc7A45hgZ2xXLOD9C++5qvrXaWMl2YemusQeVXU/4D0T9O3m5rXA3439q/ptVR1dVU+k2etwOs0VT325sXxHVf0BWCjfMZWqOgmY+UCkqrqsqk5rP76G5pfd1OdQVuM37d1N2ttU/6VJdgL+AvjotP1ZCkm2Ah5Je7xtVf1hYaf+jBY9rH0MK4DbJ1kBrAQunTLOnwAnV9W1VXUD8E2aX8hj63iPHgB8vP344zTHBE8Vq6rOqaofT9KnEbGOb79OgO/S/A6YNtbVA3c3Z4L3/4if6/cDr+kp1sQ6Yv0f4B1VdV3b5orZXmTCW88WTRKDqurKqjqsqvbtsQ/Dynf0dyhwD9JUvn0gcPKMcTZOcgZwBXBCVU0b7+9pfjDWzdKfAQUcn+TUNGVSprUb8EvgY+1U2EfTHG4yq0UPax+lqi6h+WvuIpop1Kuq6vgpw50NPCLJHZOsBJ7ATTeNTmv7qrqs/fhyYPseYvbtOYy3R6pTkrcnuRj4ayYbSQyLdQBwSVX9YJY4A17cTocdMe50X4d70bxHTk7yzSR/Om2gMMfTTWokuQPwWeBl6/0lNLGqWtsOtXcC9mqnLibtz/7AFVV16ix9Wc/Dq+pBNFN+L0ryyCnjrAAeBHy4qh4I/Jbxp02Gyh8Pa//MDDG2oflLfTeaqsabJ3nGNLGq6hzgncDxNBtNzwDWTtu3jtdYor8Jp5fkDTRTsEfNEqeq3lBVO7dxXjxDf1YCr2fGRDPgw8DdaaaCLwPeO0OsFcC2NNPUrwY+nWT69dwNaSSxROa2fEeSTWgSxFFV9bm+4rZTMCcy3drJw4AnJbmAZmruMUk+OWN/Lmn/vYJm3n+vKUOtBlYPjJCOpUkasxjrsPZFPBb4eVX9sqquBz4HPHTaYFV1eFU9uKoeCVxJM1c/q18k2QGg/Xe2KYoeJTmY5ijjv14oz9ODo4CnzvD8u9Mk/R+0Pws7AaclWXSj7zBV9Yv2j7h1wEeY/mcAmp+Dz7VTzN+jGfGPtah+8445koCB8h3tX40HAl9a5j7RZv7DgXOq6n09xLvTwpUhSW5Pc87GuZPGqarXVdVOVbUrzffq36tqqr+K275snmSLhY9pFgGnujKsqi4HLk6yUAVzX2YvDT/WYe2LuAjYO8nK9v91X2ZY9E+yXfvvLjTrEUfP2D9o3vPPaj9+FvDFHmLOLMl+NFObT6qqa2eMdc+Buwcwxft/QVWdVVXbVdWu7c/CauBB7Xtwmr7tMHD3L5nyZ6D1BWCfNu69aGrdTV/5dplHEuOU5VhSU5bv6JTkGODRNCfqrQbeXFWHTxHqYcAzgbPadQSA109w1cP6dgA+3l7NtRHw6aqa+fLVHmwPfL4dDa8Ajq6q42aIdwhwVJvwzweePW2gTHBY+yhVdXKSY4HTaKZMTme20gmfTXJH4HrgRZMuzg97jwLvoJmWeC5NheunzxDrV8AHgTsB/y/JGVX151PGeh2wKXBC+x75blW9sDPI6FhPaP+AWNd+jYvGGRVvyp/rrr49OskDaH7NXsCY77mOWEcAR7SXxf4BeNZMI7ANoSyHJOmWd/sddq67HTxZWY4fveMWKsshSZoDy/x3vElCkubVHFznZpKQpDm2IRw6JElaLiYJSVKX5R5JzMM+CWliSd7QVthcqCr6kCQva3fiLvbcsdpJc8Ed19Jk0pQf359m89TuNDuqL6apVDzOL/9x20nLa9IEYZKQgGZj4pqBKptrgKfR1GU6McmJAG1Z+1MycH5HkpcMafe4JN9JclqSz7T1ukjyjjTniZyZZLZyz9IUMsWtbyYJbYiOB3ZO8pMk/5jkUVX1AZry3/vUH4/YfUO7qWh34FFJdl+/XZqDat4IPLYtcngK8Ip2R/VfAvdrRytvu4W/RmkumCS0wWnP5Xgw8Hya0uSfaovQre/pSU6jKcNxP5pDrda3d/v5b7XlV54F3BW4Cvg9cHiSp9AceiTd8m7rtZukaVTVWuAbwDeSnMUfi+MBkGQ34FXAn1bVlUmOBIYdWRqasz0OutkDyV40xQCfRlPW+jF9fg3SOLy6SZpQmvOvByuKPoCmYNw1wBbt57akOc/iqiTb05QcXzDY7rvAw9IeQdpWxb1Xuy6xVVvQ8eU0R5VKtzxHEtLE7gB8sC29fgNwHs3U00HAcUkubdcbTqcpR30x8K2B5x+2XruDgWOSbNo+/kaaRPLFJJvRjDYmq7Im9cUqsJKkYVZut3Pd668m+/vkBx/qtwqs002SNM+WYLopydZJjk1ybpJz2r1HQzndJElzbIkWrg8Fjquqp7UHhHVuLjVJSNI86zlJJNkKeCRwMEBV/YHmBL2hnG6SpDmWmuxGc5TqKQO3568Xcjea/UUfS3J6ko+2RwUPZZKQpHk1Xe2mNVW158Bt/fPcVwAPAj5cVQ+kuVT8tV1dMElI0jzrf+F6NbC6qk5u7x9LkzSGMklI0pwKU003jVRVlwMXJ7l3+6l9gR91tXfhWpLm2dJc3XQIcFR7ZdP5wLO7GpokJGmOZQk2PFfVGcBYG+5MEpI0r5aoHtMkTBKSNMeWuwqsSUKS5plJQpLUxZGEJKmbSUKSNNSYex+WkklCkuaZSUKSNMzCjuvlZJKQpHm2zKeHmiQkaY45kpAkDeeOa0nSKFm3vK9vkpCkeeZIQpLUxTUJSdJwhVc3SZK6OZKQJHUzSUiShnHHtSSpW5VrEpKkbo4kJEndTBKSpC6OJCRJwxWwzjUJSVIXRxKSpC5ON0mSunkJrCSpiyMJSdJwHjokSerSlOVwukmS1MWT6SRJXRxJSJKGc01CktTNKrCSpBG8BFaS1G0JRhJJLgCuAdYCN1TVnl1tTRKSNK8KsnRXN+1TVWsWa2SSkKR5tsxrEhst66tLkkarCW+wKskpA7fnd0Q9PsmpHY/fyJGEJM2xKfZJrBm1xtB6eFVdkmQ74IQk51bVScMaOpKQpNuYqrqk/fcK4PPAXl1tTRKSNM+qJrstIsnmSbZY+Bh4HHB2V3unmyRpXhVLUbtpe+DzSaDJAUdX1XFdjU0SkjSnQvVeu6mqzgf2GLe9SUKS5pllOSRJnUwSkqShlmZNYiImCUmaY54nIUnqZpKQJA3neRKSpC6FSUKSNIIL15KkLi5cS5K6mSQkSUMVsM4kIUkayqubJEmjmCQkSZ1MEpKkoVyTkCR1K6jl3ShhkpCkeeZ0kyRpKKebJEkjOZKQJHUySUiShnMznSSpSwHrvLpJktTFkYQkqZNJQpI0XHkJrCSpQ0G541qS1MmRhCSpk2sSkqShqrwEVpI0giMJSVKXciQhSRrOshySpC6WCpckjeQ+CUnSMAWUIwlJ0lC1dGdcJ9kYOAW4pKr272pnkpCkObaEI4mXAucAW45qtNFSvbokqQe1brLbGJLsBPwF8NFF29YyX14lSRouyXHAqgmfthnw+4H7h1XVYevFPRb4O2AL4FVON0nSBqiq9us7ZpL9gSuq6tQkj16svdNNknTb8jDgSUkuAP4FeEyST3Y1drpJkm6j2pHEyOkmRxKSpE6OJCRJnRxJSJI6mSQkSZ1MEpKkTiYJSVInk4QkqZNJQpLUySQhSer0/wHJNM5k44gXdQAAAABJRU5ErkJggg==",
                        "text/plain": [
                            "<Figure size 432x288 with 2 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "optimal_q = env.optimal_Q_mesh()\n",
                "\n",
                "q_visu_mesh = TwoDimesionsMesh(states, actions, 0)\n",
                "\n",
                "q_visu_mesh.set_values(optimal_q)\n",
                "q_visu_mesh.show(\"Optimal q function\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Q with Fitted-Q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "__init__() got multiple values for argument 'continuous_actions'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpbo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlearnable_q\u001b[39;00m \u001b[39mimport\u001b[39;00m TableQ\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=6'>7</a>\u001b[0m data_loader_samples \u001b[39m=\u001b[39m SampleDataLoader(replay_buffer, batch_size_samples, shuffle_key)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=7'>8</a>\u001b[0m q \u001b[39m=\u001b[39m TableQ(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=8'>9</a>\u001b[0m     gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=9'>10</a>\u001b[0m     network_key\u001b[39m=\u001b[39;49mq_network_key,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=10'>11</a>\u001b[0m     random_weights_range\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=11'>12</a>\u001b[0m     random_weights_key\u001b[39m=\u001b[39;49mrandom_weights_key,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=12'>13</a>\u001b[0m     n_states\u001b[39m=\u001b[39;49mn_states,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=13'>14</a>\u001b[0m     n_actions\u001b[39m=\u001b[39;49mn_actions,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=14'>15</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate_q,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=15'>16</a>\u001b[0m     zero_initializer\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=17'>18</a>\u001b[0m validation_initial_weight \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mto_weights(q\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vincent/Darmstadt/PBO/pbo_chain_walk.ipynb#ch0000012?line=19'>20</a>\u001b[0m training_losses_q \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(max_bellman_iterations)\n",
                        "File \u001b[0;32m~/Darmstadt/PBO/pbo/networks/learnable_q.py:202\u001b[0m, in \u001b[0;36mTableQ.__init__\u001b[0;34m(self, gamma, network_key, random_weights_range, random_weights_key, n_states, n_actions, learning_rate, zero_initializer)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnetwork\u001b[39m(state: jnp\u001b[39m.\u001b[39mndarray, action: jnp\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m jnp\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    200\u001b[0m     \u001b[39mreturn\u001b[39;00m TableQNet(n_states, n_actions, zero_initializer)(state, action)\n\u001b[0;32m--> 202\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    203\u001b[0m     gamma,\n\u001b[1;32m    204\u001b[0m     network,\n\u001b[1;32m    205\u001b[0m     network_key,\n\u001b[1;32m    206\u001b[0m     random_weights_range,\n\u001b[1;32m    207\u001b[0m     random_weights_key,\n\u001b[1;32m    208\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    209\u001b[0m     n_actions,\n\u001b[1;32m    210\u001b[0m     learning_rate,\n\u001b[1;32m    211\u001b[0m     continuous_actions\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    212\u001b[0m )\n",
                        "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'continuous_actions'"
                    ]
                }
            ],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "\n",
                "from pbo.sample_collection.dataloader import SampleDataLoader\n",
                "from pbo.networks.learnable_q import TableQ\n",
                "\n",
                "\n",
                "data_loader_samples = SampleDataLoader(replay_buffer, batch_size_samples, shuffle_key)\n",
                "q = TableQ(\n",
                "    gamma=gamma,\n",
                "    network_key=q_network_key,\n",
                "    random_weights_range=None,\n",
                "    random_weights_key=random_weights_key,\n",
                "    n_states=n_states,\n",
                "    n_actions=n_actions,\n",
                "    learning_rate=learning_rate_q,\n",
                "    zero_initializer=True\n",
                ")\n",
                "validation_initial_weight = q.to_weights(q.params)\n",
                "\n",
                "training_losses_q = np.zeros(max_bellman_iterations)\n",
                "validation_losses_q = np.zeros(max_bellman_iterations)\n",
                "absording_probabilities_q = np.zeros((max_bellman_iterations, horizon))\n",
                "\n",
                "for bellman_iteration in tqdm(range(max_bellman_iterations)):\n",
                "    params_target = q.params\n",
                "\n",
                "    for step in range(fitting_steps_q):\n",
                "        data_loader_samples.shuffle()\n",
                "        for batch_samples in data_loader_samples:\n",
                "            q.params, q.optimizer_state, _ = q.learn_on_batch(q.params, params_target, q.optimizer_state, batch_samples)        \n",
                "\n",
                "    q_i = q.discretize(q.to_weights(params_target).reshape((-1, q.weights_dimension)), states, actions)[0]\n",
                "    q_i_plus_1 = q.discretize(q.to_weights(q.params).reshape((-1, q.weights_dimension)), states, actions)[0]\n",
                "    policy_q = q_i_plus_1.argmax(axis=1)\n",
                "\n",
                "    training_losses_q[bellman_iteration] = jnp.abs(env.apply_bellman_operator(q_i) - q_i_plus_1).mean()\n",
                "    validation_losses_q[bellman_iteration] = jnp.abs(optimal_q - q_i_plus_1).mean()\n",
                "    absording_probabilities_q[bellman_iteration] = env.absorbing_probability(policy_q, horizon)\n",
                "\n",
                "    print(policy_q)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimal PBO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "\n",
                "from pbo.sample_collection.dataloader import SampleDataLoader\n",
                "from pbo.networks.learnable_pbo import TabularPBO\n",
                "\n",
                "\n",
                "data_loader_samples = SampleDataLoader(replay_buffer, batch_size_samples, shuffle_key)\n",
                "\n",
                "pbo_optimal = TabularPBO(q, max_bellman_iterations, add_infinity, pbo_network_key, learning_rate, n_actions)\n",
                "pbo_optimal.params[\"TabularPBONet/linear\"][\"w\"] = gamma * env.transition_proba.T\n",
                "pbo_optimal.params[\"TabularPBONet/linear\"][\"b\"] = env.PR.T\n",
                "\n",
                "training_losses_optimal = np.zeros(max_bellman_iterations_validation)\n",
                "validation_losses_optimal = np.zeros(max_bellman_iterations_validation)\n",
                "absording_probabilities_optimal = np.zeros((max_bellman_iterations_validation, horizon))\n",
                "\n",
                "batch_iterated_weights = validation_initial_weight.reshape((1, -1))\n",
                "for bellman_iteration in range(max_bellman_iterations_validation):\n",
                "    q_i = q.discretize(batch_iterated_weights, states, actions)[0]\n",
                "    batch_iterated_weights = pbo_optimal(pbo_optimal.params, batch_iterated_weights)\n",
                "    q_i_plus_1 = q.discretize(batch_iterated_weights, states, actions)[0]\n",
                "    policy_q = q_i_plus_1.argmax(axis=1)\n",
                "\n",
                "    training_losses_optimal[bellman_iteration] = jnp.abs(env.apply_bellman_operator(q_i) - q_i_plus_1).mean()\n",
                "    validation_losses_optimal[bellman_iteration] = jnp.abs(optimal_q - q_i_plus_1).mean()\n",
                "    absording_probabilities_optimal[bellman_iteration] = env.absorbing_probability(policy_q, horizon)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Collect weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pbo.weights_collection.weights_buffer import WeightsBuffer\n",
                "\n",
                "\n",
                "weights_buffer = WeightsBuffer()\n",
                "\n",
                "# Add initial validation weights\n",
                "weights_buffer.add(validation_initial_weight)\n",
                "\n",
                "# Add randow weights\n",
                "q = TableQ(\n",
                "    gamma=gamma,\n",
                "    network_key=q_network_key,\n",
                "    random_weights_range=None,\n",
                "    random_weights_key=random_weights_key,\n",
                "    n_states=n_states,\n",
                "    n_actions=n_actions,\n",
                "    learning_rate=learning_rate_q\n",
                ")\n",
                "\n",
                "while len(weights_buffer) < n_weights:\n",
                "    weights = q.random_init_weights()\n",
                "    weights_buffer.add(weights)\n",
                "\n",
                "weights_buffer.cast_to_jax_array()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train non linear PBO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "\n",
                "from pbo.sample_collection.dataloader import SampleDataLoader\n",
                "from pbo.weights_collection.dataloader import WeightsDataLoader\n",
                "from pbo.networks.learnable_pbo import TabularPBO\n",
                "\n",
                "\n",
                "data_loader_samples = SampleDataLoader(replay_buffer, batch_size_samples, shuffle_key)\n",
                "data_loader_weights = WeightsDataLoader(weights_buffer, batch_size_weights, shuffle_key)\n",
                "pbo_tabular = TabularPBO(q, max_bellman_iterations, add_infinity_non_linear, pbo_network_key, learning_rate, n_actions)\n",
                "importance_iteration = jnp.ones(max_bellman_iterations + 1)\n",
                "importance_iteration = importance_iteration.at[-1].set(0)\n",
                "\n",
                "for _ in tqdm(range(training_steps)):\n",
                "    params_target = pbo_tabular.params\n",
                "\n",
                "    for _ in range(fitting_steps):\n",
                "        data_loader_weights.shuffle()\n",
                "        for batch_weights in data_loader_weights:\n",
                "            data_loader_samples.shuffle()\n",
                "            for batch_samples in data_loader_samples:\n",
                "                pbo_tabular.params, pbo_tabular.optimizer_state, _ = pbo_tabular.learn_on_batch(\n",
                "                    pbo_tabular.params, params_target, pbo_tabular.optimizer_state, batch_weights, batch_samples, importance_iteration\n",
                "                )\n",
                "\n",
                "training_losses_tabular = np.zeros(max_bellman_iterations_validation)\n",
                "validation_losses_tabular = np.zeros(max_bellman_iterations_validation)\n",
                "absording_probabilities_tabular = np.zeros((max_bellman_iterations_validation, horizon))\n",
                "\n",
                "batch_iterated_weights = validation_initial_weight.reshape((1, -1))\n",
                "for bellman_iteration in range(max_bellman_iterations_validation):\n",
                "    q_i = q.discretize(batch_iterated_weights, states, actions)[0]\n",
                "    batch_iterated_weights = pbo_tabular(pbo_tabular.params, batch_iterated_weights)\n",
                "    q_i_plus_1 = q.discretize(batch_iterated_weights, states, actions)[0]\n",
                "    policy_q = q_i_plus_1.argmax(axis=1)\n",
                "\n",
                "    training_losses_tabular[bellman_iteration] = jnp.abs(env.apply_bellman_operator(q_i) - q_i_plus_1).mean()\n",
                "    validation_losses_tabular[bellman_iteration] = jnp.abs(optimal_q - q_i_plus_1).mean()\n",
                "    absording_probabilities_tabular[bellman_iteration] = env.absorbing_probability(policy_q, horizon)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train linear PBO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "\n",
                "from pbo.sample_collection.dataloader import SampleDataLoader\n",
                "from pbo.weights_collection.dataloader import WeightsDataLoader\n",
                "from pbo.networks.learnable_pbo import LinearPBO\n",
                "\n",
                "\n",
                "data_loader_samples = SampleDataLoader(replay_buffer, batch_size_samples, shuffle_key)\n",
                "data_loader_weights = WeightsDataLoader(weights_buffer, batch_size_weights, shuffle_key)\n",
                "pbo = LinearPBO(q, max_bellman_iterations, add_infinity_linear, pbo_network_key, learning_rate)  # infinity added\n",
                "importance_iteration = jnp.ones(max_bellman_iterations + 1)\n",
                "\n",
                "\n",
                "for _ in tqdm(range(training_steps)):\n",
                "    params_target = pbo.params\n",
                "    for _ in range(fitting_steps):\n",
                "        data_loader_weights.shuffle()\n",
                "        for batch_weights in data_loader_weights:\n",
                "            data_loader_samples.shuffle()\n",
                "            for batch_samples in data_loader_samples:\n",
                "                pbo.params, pbo.optimizer_state, _ = pbo.learn_on_batch(\n",
                "                    pbo.params, params_target, pbo.optimizer_state, batch_weights, batch_samples, importance_iteration\n",
                "                )\n",
                "\n",
                "training_losses = np.zeros(max_bellman_iterations_validation)\n",
                "validation_losses = np.zeros(max_bellman_iterations_validation)\n",
                "absording_probabilities = np.zeros((max_bellman_iterations_validation, horizon))\n",
                "\n",
                "batch_iterated_weights = validation_initial_weight.reshape((1, -1))\n",
                "for bellman_iteration in range(max_bellman_iterations_validation):\n",
                "    q_i = q.discretize(batch_iterated_weights, states, actions)[0]\n",
                "    batch_iterated_weights = pbo(pbo.params, batch_iterated_weights)\n",
                "    q_i_plus_1 = q.discretize(batch_iterated_weights, states, actions)[0]\n",
                "    policy_q = q_i_plus_1.argmax(axis=1)\n",
                "\n",
                "    training_losses[bellman_iteration] = jnp.abs(env.apply_bellman_operator(q_i) - q_i_plus_1).mean()\n",
                "    validation_losses[bellman_iteration] = jnp.abs(optimal_q - q_i_plus_1).mean()\n",
                "    absording_probabilities[bellman_iteration] = env.absorbing_probability(policy_q, horizon)\n",
                "\n",
                "    print(policy_q)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualize errors in Q functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt \n",
                "\n",
                "iterations = range(1, max_bellman_iterations_validation + 1)\n",
                "\n",
                "plt.plot(iterations, validation_losses, label=\"pbo linear\", color=\"green\")\n",
                "plt.plot(iterations, validation_losses_tabular, label=\"pbo max-linear\", color=\"grey\", linestyle=\"--\")\n",
                "plt.plot(iterations, validation_losses_optimal, label=\"pbo optimal\", color=\"black\")\n",
                "plt.plot(range(1, max_bellman_iterations + 1), validation_losses_q, label=\"FQI\", color=\"red\", linewidth=4)\n",
                "plt.vlines(max_bellman_iterations, 0, np.max(validation_losses_q), color=\"black\", linestyle=\"--\")\n",
                "\n",
                "plt.xticks(iterations)\n",
                "plt.xlabel(\"iterations\")\n",
                "\n",
                "plt.title(r\"$|| Q^* - Q_i ||_1$\")\n",
                "_ = plt.legend()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(iterations, training_losses, label=\"pbo linear\", color=\"green\")\n",
                "plt.plot(iterations, training_losses_tabular, label=\"pbo max-linear\", color=\"grey\")\n",
                "plt.plot(iterations, training_losses_optimal, label=\"pbo optimal\", color=\"black\")\n",
                "plt.plot(range(1, max_bellman_iterations + 1), training_losses_q, label=\"FQI\", color=\"red\")\n",
                "plt.vlines(max_bellman_iterations, 0, np.maximum(np.max(training_losses_q), np.max(training_losses)), color=\"black\", linestyle=\"--\")\n",
                "\n",
                "plt.xticks(iterations)\n",
                "plt.xlabel(\"iterations\")\n",
                "\n",
                "plt.title(r\"$|| \\Gamma^*Q_{i-1} - Q_i ||_1$\")\n",
                "_ = plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Understanding the learning process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "empirical_transition_proba = np.zeros((n_states, n_states * n_actions))\n",
                "\n",
                "for idx_sample in range(len(replay_buffer.states)):\n",
                "    state = replay_buffer.states[idx_sample, 0]\n",
                "    action = replay_buffer.actions[idx_sample, 0]\n",
                "    next_state = replay_buffer.next_states[idx_sample, 0]\n",
                "\n",
                "    empirical_transition_proba[next_state, state * n_actions + action] += 1 \n",
                "\n",
                "empirical_transition_proba /= n_repetitions\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.linalg.norm(empirical_transition_proba - pbo_tabular.params[\"TabularPBONet/linear\"][\"w\"] / gamma)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualize errors in preformances"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iteration = 5\n",
                "time = range(1, horizon + 1)\n",
                "\n",
                "\n",
                "plt.plot(time, absording_probabilities[iteration], label=\"pbo linear\", color=\"green\")\n",
                "plt.plot(time, absording_probabilities_tabular[iteration], label=\"pbo max-linear\", color=\"grey\", linestyle=\"--\")\n",
                "plt.plot(time, absording_probabilities_optimal[iteration], label=\"pbo optimal\", color=\"black\")\n",
                "plt.plot(time, absording_probabilities_q[min([iteration, max_bellman_iterations - 1])], label=\"FQI\", color=\"red\")\n",
                "\n",
                "plt.xticks(time)\n",
                "plt.xlabel(\"time\")\n",
                "\n",
                "plt.title(r\"$P^{\\pi}(s_i =$ absorbing state)\")\n",
                "_ = plt.legend()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iteration = 1\n",
                "\n",
                "\n",
                "plt.plot(iterations, absording_probabilities[:, -1], label=\"pbo linear\", color=\"green\")\n",
                "plt.plot(iterations, absording_probabilities_tabular[:, -1], label=\"pbo max-linear\", color=\"grey\", linestyle=\"--\")\n",
                "plt.plot(iterations, absording_probabilities_optimal[:, -1], label=\"pbo optimal\", color=\"black\")\n",
                "plt.plot(range(1, max_bellman_iterations + 1), absording_probabilities_q[:, -1], label=\"FQI\", color=\"red\")\n",
                "plt.vlines(max_bellman_iterations, 0, 1, color=\"black\", linestyle=\"--\")\n",
                "\n",
                "plt.xticks(iterations)\n",
                "plt.xlabel(\"iterations\")\n",
                "\n",
                "plt.title(r\"$P^{\\pi}(s_i =$ absorbing state)\" + f\" after {horizon} steps\")\n",
                "_ = plt.legend()"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "1432d270abb514d077d760a4c8d2edd41cc0752b595b0513fca29951003961c1"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 ('env': venv)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
